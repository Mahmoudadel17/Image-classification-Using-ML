{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mahmoud Adel Mamdouh 20200500 \n",
    "# Mohamed Tarek Fathi  20200794\n",
    "# Dina Othman Emam     20200173\n",
    "# Habiba Ayman Eltahry 20200140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
      "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_data = pd.read_csv('mnist_train.csv')\n",
    "test_data = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "# Explore the first few rows\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique classes: 10\n",
      "Number of features: 784\n"
     ]
    }
   ],
   "source": [
    "unique_classes = train_data['label'].nunique()\n",
    "print(\"Number of unique classes:\", unique_classes)\n",
    "\n",
    "# Check the number of features\n",
    "num_features = len(train_data.columns) - 1  # subtract 1 for the label column\n",
    "print(\"Number of features:\", num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in training data:\\n\", train_data.isnull().sum())\n",
    "print(\" \")\n",
    "print(\"Missing values in test data:\\n\", test_data.isnull().sum())\n",
    "print(\" \")\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "print(\"Missing values in training data after drop na :\\n\", train_data.isnull().sum())\n",
    "print(\"Missing values in test data after drop na :\\n\", test_data.isnull().sum())\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:, 1:] /= 255.0\n",
    "test_data.iloc[:, 1:] /= 255.0\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get rows with unique values in the specified column\n",
    "unique_records_df = train_data.drop_duplicates(subset=['label'])\n",
    "\n",
    "\n",
    "def resize_images(data):\n",
    "    return data.iloc[:, 1:].values.reshape(-1, 28, 28)\n",
    "\n",
    "resized_unique_train_images = resize_images(unique_records_df)\n",
    "\n",
    "\n",
    "for image in resized_unique_train_images:\n",
    "  plt.imshow(image, cmap='gray')\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data.iloc[:, 1:], train_data['label'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'n_neighbors': np.arange(2, 9)}\n",
    "param_grid\n",
    "# Initialize the grid search\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters: \", best_params)\n",
    "\n",
    "# Make predictions\n",
    "predictions = grid_search.predict(X_val)\n",
    "\n",
    "# Print the accuracy and confusion matrix\n",
    "print(\"Accuracy: \", accuracy_score(y_val, predictions))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_val, predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define the first model\n",
    "model1 = Sequential([\n",
    "   Dense(32, activation='relu', input_shape=(num_features,)),\n",
    "   Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the first model\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the second model\n",
    "model2 = Sequential([\n",
    "   Dense(64, activation='relu', input_shape=(num_features,)),\n",
    "   Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the second model\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "\n",
    "# Fit the first model\n",
    "history1 = model1.fit(X_train, y_train_cat, epochs=10, batch_size=32, validation_data=(X_val, y_val_cat))\n",
    "\n",
    "# Fit the second model\n",
    "history2 = model2.fit(X_train, y_train_cat, epochs=10, batch_size=64, validation_data=(X_val, y_val_cat))\n",
    "\n",
    "# Evaluate the first model\n",
    "loss1, accuracy1 = model1.evaluate(X_val, y_val_cat)\n",
    "\n",
    "# Evaluate the second model\n",
    "loss2, accuracy2 = model2.evaluate(X_val, y_val_cat)\n",
    "\n",
    "print(\"Model 1 Accuracy: \", accuracy1)\n",
    "print(\"Model 2 Accuracy: \", accuracy2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the best model\n",
    "if accuracy1 > accuracy2:\n",
    "   model1.save('best_model.h5')\n",
    "else:\n",
    "   model2.save('best_model.h5')\n",
    "\n",
    "# Reload the best model\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "\n",
    "# Get the first record (row) in the dataset\n",
    "first_record = test_data.iloc[0]\n",
    "\n",
    "# Extract pixel values (assuming they start from the second column)\n",
    "image = first_record[1:].values.reshape(28, 28)\n",
    "\n",
    "# Plot the image\n",
    "print(\"first image data in test.\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "# Use the best model to make predictions on the test data\n",
    "y_test_cat = to_categorical(test_data['label'])\n",
    "predictions = best_model.predict(test_data.iloc[:, 1:])\n",
    "\n",
    "\n",
    "\n",
    "# Assuming y_test_cat is in one-hot encoded format\n",
    "y_test_labels = np.argmax(y_test_cat, axis=1)\n",
    "predictions_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"\")\n",
    "print(\"first predictions_labels label: \",predictions_labels[0])\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test_labels, predictions_labels))\n",
    "print(\"\")\n",
    "\n",
    "# Calculate accuracy using accuracy_score\n",
    "accuracy = accuracy_score(y_test_labels, predictions_labels)\n",
    "\n",
    "# Print the confusion matrix and accuracy\n",
    "\n",
    "print(\"Accuracy: {:.2%}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
